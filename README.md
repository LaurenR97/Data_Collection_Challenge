# Data_Collection_Challenge

Overview
This project involves a full web-scraping and data analysis task. The focus is on identifying HTML elements on a page, determining their id and class attributes, and using this knowledge to extract information via both automated browsing with Splinter and HTML parsing with Beautiful Soup. The project covers scraping various types of information, including HTML tables and recurring elements like multiple news articles on a webpage.

The core skills being developed include collecting data, organizing and storing data, analyzing data, and visually communicating insights.

Deliverables
This assignment consists of two technical products:

Deliverable 1: Scrape titles and preview text from Mars news articles.
Deliverable 2: Scrape and analyze Mars weather data, which exists in a table.

Instructions
Part 1: Scrape Titles and Preview Text from Mars News
Open the Jupyter Notebook in the starter code folder named part_1_mars_news.ipynb. Follow the steps below to scrape the Mars News website.

Use Automated Browsing: Visit the Mars news site and inspect the page to identify which elements to scrape.

Scrape Titles and Preview Text: Write code to scrape the titles and preview text of Mars news articles. Ensure that the code can extract these elements correctly.

Part 2: Scrape and Analyze Mars Weather Data
Open the Jupyter Notebook: Use the starter code folder named part_2_mars_weather.ipynb.

Scrape the Mars Weather Data: Write code to scrape the Mars weather data table. Use Beautiful Soup to parse the HTML and extract the data.

Analyze the Weather Data: Convert the scraped data into a Pandas DataFrame and perform analysis. Generate insights and visualizations based on the data.

